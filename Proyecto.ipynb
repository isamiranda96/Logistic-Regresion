{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto\n",
    "\n",
    "\n",
    "En este proyecto vamos a hacer machine learning aplicado al ámbito medico ,específicamente diagnostico medico.\n",
    "Vamos a crear una aplicación que ayuda a diagnosticar si un tumor de seno es cancerígeno (maligno) o no (benigno)   .\n",
    "Para lograr esto vamos a utilizar un set de datos recopilado por diversos médicos , el cual contiene características de tumores de seno y el diagnostico final . Este es un problema de clasificación binaria ya que solo tenemos dos clases(maligno o benigno), se va a implementar regresión logística para obtener la probabilidad de que el tumor sea maligno.\n",
    "\n",
    "<img src=\"images/ai_cancer.png\" width=\"300\">\n",
    "\n",
    "Según lo visto en la clase en este proyecto el estudiante hará  todo el proceso de entrenamiento, evaluación y selección del modelo de machine learning(pasos 1 al 5 del diagrama de flujo de ejemplo) ,luego de seleccionar el mejor va a exportar el modelo (como fue explicado en la clase deployment/despliegue de modelos y va a entregarlo al profesor) ya que  este será utilizado dentro de una aplicación móvil (desarrollada por el profesor, paso 6 del diagrama )\n",
    "\n",
    "\n",
    "<img src=\"images/diagrama.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import datetime\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registro de Experimentos\n",
    "En machine learning y ciencia de datos es importante tener un registro de los resultados de cada experimento realizado, así como la configuración del sistema(tal como learning-rate, numero de iteraciones, cantidad de observaciones y features, etc) que llevo a determinados resultados, esto porque el proceso puede llegar a ser muy iterativo y nos es útil saber en todo momento que caso tuvo los mejores resultados. Por esta razón en este proyecto utilizamos una bitácora o log-book científico en el cual tenemos la configuración de nuestros modelos y los resultados(métricas de evaluación) de cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_book = helper.load_log_book()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez la bitacora contenga informacion ,puedes consultarla en cualquier celda usando:\n",
    "\n",
    "helper.print_log_book(log_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para guardar la bitacora (una vez has capturado el resultado de los experimentos que realizaremos) usaremos el siguiente codigo(hay mas detalles mas adelante)\n",
    "\n",
    "helper.guardar_log_book(log_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carnet estudiante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " La aplicación móvil resultante tendrá un modelo por estudiante, por lo cual es importante identificar a que estudiante pertenece cada modelo, por esta razón  en el proceso de exportar el modelo el archivo resultante tendrá en su nombre el carnet del estudiante. \n",
    " \n",
    " En una variable deben ingresar su numero de carnet, para que al exportar el modelo el archivo se llame `carnet+\"model.csv\"`. Por ejemplo 200818835model.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carnet = \"200818835\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Data Set\n",
    "\n",
    "El dataset que usaremos contiene varias características(features) , más adelante encontraras instrucciones de cómo trabajar con estas. En el siguiente enlace puedes acceder a mayor información y detalles del dataset.\n",
    "\n",
    "[Link al set de datos](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer)\n",
    "\n",
    "#### Data Set Information:\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. A few of the images can be found at [Web Link] \n",
    "\n",
    "Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes. \n",
    "\n",
    "The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es un problema de clasificacion binario por que que existen solo dos posibles valores(predecimos tumores cancerigenos de seno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El data set tiene varios features, por lo  que debemos experimentar con diferentes features y analizar los resultados, en esta celda vamos a imprimir los nombres de las features que poseemos.\n",
    "\n",
    "En este [link](https://goo.gl/U2Uwz2) podemos encontrar mas información sobre las features.\n",
    "\n",
    "Nota: Aunque a lo largo del proyecto, usaremos distintas features para entrenar diversos modelos y entender cómo funciona el proceso de ML y el impacto del uso de diversas features, en el resultado final (el modelo que será exportado e integrado a la aplicación móvil) solo usaremos las primeras 5 features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "muestra de las primeras 5 labels/etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "las features para estos 5 casos de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data[0:5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de Regresión Logística "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hipótesis\n",
    "Función Sigmoid:\n",
    "\n",
    "$sig(t) = {\\frac {1} {1 + e^{-t}}}$\n",
    "\n",
    "Combinamos la función sigmoid/lógistica con la  hipótesis conocida (aprendida en regresión lineal) y tenemos la nueva hipótesis para clasificación con regresión lógistica:\n",
    "\n",
    "$z = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + \\ldots + \\theta_{n}x_{n}$\n",
    "\n",
    "$g(z) = {\\frac {1} {1 + e^{-z}}}$\n",
    "\n",
    "** Hipótesis para clasificación con regresión logística: **\n",
    "\n",
    "$h_{\\theta}(x) = {\\frac {1} {1 + e^{-(\\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + \\ldots + \\theta_{n}x_{n})}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Sigmoid \n",
    "\n",
    "def sigmoid(z):\n",
    "    ### INICIO: TU CODIGO AQUI:  (~1 linea)###\n",
    "    s = \n",
    "    ### FIN ##\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validando nuestra funcion sigmoid\n",
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))\n",
    "print (\"sigmoid(9.2) = \" + str(sigmoid(9.2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados esperados\n",
    "\n",
    "**sigmoid(0)** = 0.5\n",
    "\n",
    "**sigmoid(9.2)** = 0.999898970806\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementado la hipótesis/modelo para clasificación con regresión logística\n",
    "\n",
    "** Hipótesis para clasificación con regresión logística: **\n",
    "\n",
    "$h_{\\theta}(x) = {\\frac {1} {1 + e^{-(\\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + \\ldots + \\theta_{n}x_{n})}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hipotesis(features, theta_values):\n",
    "    ## Calculo de la hipotesis de froma vectorizada,producto punto entre el vector de features y el vector de parametros theta ##\n",
    "    z = features.dot(theta_values)\n",
    "    \n",
    "    ### INICIO: TU CODIGO AQUI:  (~1 linea)###\n",
    "    h = \n",
    "    ### FIN ##\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas de evaluación\n",
    "\n",
    "Tal como lo vimos en la clase 22: evaluación , utilizamos diversas métricas para evaluar y reportar la exactitud y rendimiento de nuestros modelos de machine learning. En clasificación usamos el costo: cross-entropy para entrenar, pero evaluamos y reportamos diversas métricas mas ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costo\n",
    "\n",
    "El proceso de gradient descent busca minimizar la siguiente función de costo en función de los parámetros theta, y así encontrar los parámetros que producen una hipótesis optima. \n",
    "\n",
    "El costo mide que tan buena o mala es una hipótesis por lo cual esperamos que este disminuya durante el entrenamiento.\n",
    "\n",
    "$J(\\Theta) = - {\\frac {1}{m}}\\sum _{i=1}^{m} y \\log(h(x)) + (1-y)\\log(1-h(x))$\n",
    "\n",
    "Utiliza la funcion log de numpy, Ejemplo:\n",
    "`np.log(y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def costo(X, theta_vector, y):\n",
    "    m = len(y)\n",
    "    \n",
    "    ### INICIO: TU CODIGO AQUI:  (~2 lineas)###\n",
    "    y_hat = \n",
    "    \n",
    "    costo = \n",
    "    ### FIN ##\n",
    "    \n",
    "    return costo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score\n",
    "\n",
    "Implementa la funcion de accuracy utlizando sklearn(puedes utilizar como referencia la clase 22: evaluación )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(X, theta_vector, y):\n",
    "\n",
    "    hipotesis = get_hipotesis(X, theta_vector)\n",
    "    \n",
    "    # Convertimos el resultado probabilistico a deterministico (0 1)\n",
    "    y_pred = [1 if (y >= 0.5) else 0 for y in hipotesis ]\n",
    "    \n",
    "    ### INICIO: TU CODIGO AQUI:  (~1 linea)###\n",
    "    acc_score = \n",
    "    ### FIN ##\n",
    "    \n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score\n",
    "\n",
    "Implementa la funcion de f1_score utlizando sklearn(puedes utilizar como referencia la clase 22: evaluación )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1(X, theta_vector, y):\n",
    "\n",
    "    hipotesis = get_hipotesis(X, theta_vector)\n",
    "\n",
    "    # Convertimos el resultado probabilistico a deterministico (0 1)    \n",
    "    y_pred = [1 if (y >= 0.5) else 0 for y in hipotesis ]\n",
    "    \n",
    "    ## INICIO: TU CODIGO AQUI:  (~1 linea)###\n",
    "    f1 = \n",
    "    ### FIN ##\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision Score\n",
    "\n",
    "Implementa la funcion de precision_score utlizando sklearn(puedes utilizar como referencia la clase 22: evaluación )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(X, theta_vector, y):\n",
    "\n",
    "    hipotesis = get_hipotesis(X, theta_vector)\n",
    "\n",
    "    # Convertimos el resultado probabilistico a deterministico (0 1)    \n",
    "    y_pred = [1 if (y >= 0.5) else 0 for y in hipotesis ]\n",
    "    \n",
    "    ## INICIO: TU CODIGO AQUI:  (~1 linea)###\n",
    "    precision = \n",
    "    ### FIN ##\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall Score\n",
    "\n",
    "Implementa la funcion de recall_score utlizando sklearn(puedes utilizar como referencia la clase 22: evaluación )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall(X, theta_vector, y):\n",
    "\n",
    "    hipotesis = get_hipotesis(X, theta_vector)\n",
    "\n",
    "    # Convertimos el resultado probabilistico a deterministico (0 1)    \n",
    "    y_pred = [1 if (y >= 0.5) else 0 for y in hipotesis ]\n",
    "    \n",
    "    ## INICIO: TU CODIGO AQUI:  (~1 linea)###\n",
    "    reacall = \n",
    "    ### FIN ##\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-procesamiento\n",
    "\n",
    "En Machine learning, la fase de pre-procesamiento(incluyendo feature engineering) de datos puede llegar a abarcar el 70% o más del tiempo de un proyecto , pero este es un tema que se profundiza en otros cursos del área de ciencia de datos por lo cual en este proyecto solo vamos a realizar como pre-procesamiento una normalización de features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarización o Z-score Normalizacion \n",
    "\n",
    "El objetivo de la normalización es ayudar a gradient descent a encontrar el mínimo del costo mas rápido y fácilmente , esto se logra a través de convertir las features de manera que tengan media = 0 y desviación estándar de 1 , similar a una distribución de probabilidad normal(gaussiana).\n",
    "\n",
    "Lo calculamos utilizando:\n",
    "\n",
    "$z = {\\frac {x - \\mu} {\\sigma}}$\n",
    "\n",
    "Donde $\\mu$ es la media y $\\sigma$ es la desviacion estandard\n",
    "\n",
    "##### Comentario opcional:\n",
    "el Z-score en el nombre concuerda con el uso de \"z-scores\" en estadística cuando se hace estadística inferencial(prueba de hipótesis e intervalos de confianza)\n",
    "\n",
    "Implementa la funcion de normalizacion sin utlizar sklearn solo puedes utilizar numpy.\n",
    "\n",
    "Para utilizar la columna de features, utilizamos `features[:,i]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizar(features):\n",
    "    std = 1\n",
    "    media = 0\n",
    "    \n",
    "    # Utilizamos el ciclo, para normalizar cada feature(una iteracion por feature)\n",
    "    for i in list(range(0, features.shape[1])):\n",
    "        ### INICIO: TU CODIGO AQUI:  (~3 lineas)###\n",
    "        std = \n",
    "        media = \n",
    "        features[:,i] = \n",
    "        ### FIN ##\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion\n",
    "\n",
    "Una vez entrenado, el modelo de ML se utiliza para realizar predicciones ,en este proyecto realizaremos predicciones en un train y un test set(no usaremos cross-validation set)  .Una  vez exportado y entregado el modelo al profesor, el modelo realizara predicciones dentro de una aplicación móvil . \n",
    "\n",
    "La siguiente función la vamos a utilizar para realizar predicciones a lo largo del proyecto(y así poder medir contra los datos reales para realizar evaluación), no hay que cambiar nada del código, solo ejecuta la celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediccion(x, theta_vector, normalizar_valores):\n",
    "    numero_features = x.shape[1] + 1\n",
    "    \n",
    "    if (normalizar_valores):\n",
    "        x = normalizar(x)\n",
    "    \n",
    "    x_features = np.ones((x.shape[0], numero_features))\n",
    "    x_features[:,:-1] = x\n",
    "\n",
    "    \n",
    "    y_hat = get_hipotesis(x_features, theta_vector)\n",
    "    \n",
    "    return np.array([1 if (y >= 0.5) else 0 for y in y_hat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Gradient descent es el algoritmo o método de optimización matemática que nos permite realizar el “entrenamiento” de nuestro modelos, ya que minimiza el costo y nos devuelve los parámetros del modelo óptimos.\n",
    "\n",
    "En la siguiente celda, debes implementar gradient descent tal como visto en clase y practicado en las tareas .\n",
    "\n",
    "Lo definimos e implementamos dentro de una función de Python para que podamos ejecutarlo(“llamarlo”) múltiples veces con distintos parámetros, sin tener que volver a programarlo cada vez , esto nos será útil para experimentar y entrenar varios modelos.\n",
    "\n",
    "Repetir{\n",
    "\n",
    "$\\theta_{j} := \\theta _{j} - \\alpha {\\frac {1}{m}} \\sum _{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})x^{(i)}_{j}$\n",
    "\n",
    "}\n",
    "        \n",
    "Simultaneamente para cada $j = 0,\\ldots,n $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta_vector, alpha, iterations, X_test, y_test, nombre_modelo):\n",
    "    global log_book\n",
    "    m = len(y)  #numero de ejemplos de entrenamiento\n",
    "\n",
    "    ## Las siguientes 3 lineas de codigo crean listas vacias para almacenar el costo y accuracy obtenido en cada iteracion\n",
    "    ## Se espera que el costo disminuya y el accuracy aumente\n",
    "    cost_vect = []\n",
    "    accuracy_vect = []\n",
    "    accuracy_vect_test = []\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        '''\n",
    "        IMPLELEMTA TU CODIGO AQUI, llama a la funcion para calcular la hipotesis,es decir calcular h(x)\n",
    "        que se implemento mas arriba. Parametros matriz de features X y el vector\n",
    "        con los valores Theta (~1 linea)\n",
    "        '''\n",
    "        hipotesis = \n",
    "\n",
    "\n",
    "        theta_vector_temp = [] # vector que guarda los parametros theta temporales\n",
    "        \n",
    "        # Utilizamos un ciclo para realizar la actualizacion de gradient descent una vez para cada parametro\n",
    "        # En cada iteracion \"i\" guarda el numero de parametro theta, y la varaible \"theta\" guarda el parametro como tal\n",
    "        for i, theta in enumerate(theta_vector):\n",
    "            '''\n",
    "            IMPLELEMTA TU CODIGO AQUI, adentro de este ciclo vamos a calcular\n",
    "            elnuevo valor de Theta[i], utilizando la formula de la celda de arriba\n",
    "            Recuerda que para multiplicar por utilizamos X[:,i]  (~1 linea)\n",
    "            '''\n",
    "            nuevo_theta =  \n",
    "\n",
    "            ### aqui agregamos el nuevo valor the theta[i] a un vector temporal\n",
    "            theta_vector_temp.append(nuevo_theta)\n",
    "\n",
    "\n",
    "        ## Actualizamos el vector theta con los nuevos valores\n",
    "        theta_vector = theta_vector_temp\n",
    "\n",
    "        # En las sigiuentes lineas calculamos las metricas de evaluacion en cada iteracion(aplicadas al train-set)\n",
    "        '''\n",
    "        IMPLEMENTA TU CODIGO AQUI, llama a la funcion de costo (~1 linea)\n",
    "        '''\n",
    "        cost = \n",
    "        \n",
    "        '''\n",
    "        IMPLEMENTA TU CODIGO AQUI, utiliza Accuracy que se definio arriba (~1 linea)\n",
    "        '''\n",
    "        acc_score = \n",
    "        \n",
    "        '''\n",
    "        IMPLEMENTA TU CODIGO AQUI, utiliza f1 score que se definio arriba (~1 linea)\n",
    "        '''\n",
    "        f1_training = \n",
    "\n",
    "        '''\n",
    "        IMPLEMENTA TU CODIGO AQUI, utiliza precision score que se definio arriba (~1 linea)\n",
    "        '''\n",
    "        precision_training = \n",
    "        \n",
    "        '''\n",
    "        IMPLEMENTA TU CODIGO AQUI, utiliza recall score que se definio arriba (~1 linea)\n",
    "        '''\n",
    "        recall_training = \n",
    "        \n",
    "        \n",
    "        ## En las siguientes lineas calculamos las metricas de evaluacion aplicadas al test-set, este codigo no hay que cambiarlo ####\n",
    "        y_predict = prediccion(X_test, theta_vector, True)\n",
    "        acc_test = accuracy_score(y_predict, y_test)\n",
    "        accuracy_vect_test.append(acc_test)\n",
    "        f1_score_test = f1_score(y_predict, y_test)\n",
    "        precision_test = precision_score(y_test, y_predict)\n",
    "        recall_test = recall_score(y_test, y_predict)\n",
    "        \n",
    "        ## Guardando el valor del costo para graficarlo, este codigo no hay que cambiarlo ##\n",
    "        cost_vect.append(cost)\n",
    "        accuracy_vect.append(acc_score)\n",
    "        \n",
    "        n =  ### Ingresa aqui cada cuantas iteraciones quieres que se imprima el valor de las metricas ###\n",
    "        \n",
    "        ## Este codigo no hay que modificarlo ##\n",
    "        if(iteration % n == 0):\n",
    "            print('#####################')\n",
    "            print('TRAINING: [Iteracion: ', iteration,' Costo: ', cost, \\\n",
    "                  ' Accuracy:', acc_score,' F1 Score:',f1_training, \\\n",
    "                  'Precision training:', precision_training, 'Recall training:', recall_training,']')\n",
    "            print('TEST: [Iteracion: ', iteration,'Accuracy:', acc_test, \\\n",
    "                  ' F1 Score:', f1_score_test, 'Precision Test:', precision_test,'Recall Test:', recall_test,']')\n",
    "        \n",
    "    ## Log book, este codigo no hay que cambiarlo, sirve para guardar en la bitacora los resultados del experimento ##\n",
    "    nombre_modelo = nombre_modelo + '_'+datetime.datetime.now().strftime(\"%d%H%M%f\")\n",
    "    numero_features = X.shape[1] - 1\n",
    "    experiment = np.array([nombre_modelo, numero_features, m, alpha, iterations, accuracy_vect[-1], \\\n",
    "                           accuracy_vect_test[-1], f1_score_test, precision_test, \\\n",
    "                           recall_test,theta_vector], dtype=object)\n",
    "    log_book = np.vstack([log_book, experiment])\n",
    "        \n",
    "    return theta_vector, cost_vect, accuracy_vect,accuracy_vect_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividimos la data en training y test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal como visto en la clase 23, nos sirve para evaluar objetivamente el rendimiento de nuestros modelos en datos que nunca ha visto durante su entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, stratify=data.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento\n",
    "\n",
    "## Features a utilizar\n",
    "A continuación, vamos a entrenar varios modelos, vamos a utilizar las funciones que creamos previamente.\n",
    "Es importante experimentar con diferentes features,diverso tamaño del training set, y diversos hyper-parametros(learning rate e iteraciones)\n",
    "\n",
    "En este proyecto como máximo vamos a utilizar 5 features(pero en algunos experimentos usaremos menos) de manera obligatoria, pero de forma opcional se recomienda experimentar con más y diversas combinaciones ,esto para practicar y obtener experiencia con ML. \n",
    "\n",
    "También vamos a utilizar diferente número de ejemplos en el set de datos, diferente número de iteraciones y diferente learning rate . Todas estas distintas configuraciones serán almacenadas en el log-book(bitácora) automáticamente .\n",
    "\n",
    "En este proyecto solo vamos a utilizar las primeras 5 features  en este orden:\n",
    "\n",
    "`['mean radius', 'mean texture', 'mean perimeter', 'mean area','mean smoothness']`\n",
    "\n",
    "La razón por las que usaremos estas 5 features específicamente(y en este orden) en el modelo final(el que será exportado) es que estas features son las que serán utilizadas en la aplicación móvil en la cual integraremos el modelo(y tendremos en la interfaz de usuario de la aplicación componentes para ingresar valores para estas features),ero como se mencionó se recomienda experimentar y evaluar resultados con distintas features y distinto número  de ellas .\n",
    "\n",
    "## Descripcion del entrenamiento\n",
    "El entrenamiento de cada modelo se compone básicamente de tres pasos, sampleo bootstrap, escoger las features y ejecutar el entrenamiento llamando a la función de gradient descent que ya creamos.\n",
    "\n",
    "En el primer paso vamos a utilizar la función resample para hacer un sampleo del set de datos de entrenamiento, debemos definir el numero de samples que queremos utilizar.\n",
    "\n",
    "En el segundo paso, en un arreglo vamos a definir el nombre de las features que queremos utilizar para entrenar el modelo.\n",
    "En el tercer paso ejecutamos la función gradient descent.\n",
    "\n",
    "Por ultimo vamos a obtener el accuracy del modelo y vamos a imprimir la matriz de confusión, imprimiremos el precisión y el recall del modelo para entender mejor los resultados y tener una mejor idea de que tan bien clasifica nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento modelo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampleo bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m1, Y_train_m1 = resample(X_train, y_train, n_samples = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar Features\n",
    "Solo seleccionar los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Ingresa en la lista el nombre de las fatrues que quieres utlizar en este modelo (~1 linea)\n",
    "'''\n",
    "features_filtro = ['mean radius', 'mean smoothness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m1 = helper.fitrar_nombre(X_train_m1,data.feature_names,features_filtro)\n",
    "X_test_features = helper.fitrar_nombre(X_test,data.feature_names,features_filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Numero de iteracions ##\n",
    "iterations = 500  # Define el numero de iteraciones #\n",
    "\n",
    "## Alpha ##\n",
    "alpha = 0.01 # Define el valor de alpha #\n",
    "\n",
    "#### No hay que cambiar el codigo despues de esta linea #####\n",
    "## Numero de feautres ##\n",
    "numero_features = X_train_m1.shape[1] + 1\n",
    "\n",
    "## Creamos un vector donde se almacenan los valores de Theta,\n",
    "## lo inicializamos con numeros aleatorios\n",
    "theta_vector = np.random.rand(numero_features)\n",
    "\n",
    "## Normaliza las features de X_train_features (~1 linea) ##\n",
    "X_train_m1 = \n",
    "\n",
    "# Creando la Matriz X de features, \n",
    "# utilizamos np.ones para agregar el valor constante '1' que es el bias o feature 0\n",
    "X_train_features = np.ones((X_train_m1.shape[0], numero_features))\n",
    "X_train_features[:,:-1] = X_train_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_1_theta_values, cost_vect, acc_vect, acc_vect_test = \\\n",
    "gradient_descent(X_train_features, Y_train_m1, theta_vector, alpha, iterations, X_test_features, y_test, 'modelo_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Funcion para graficar el costo y  accuracy durante cada iteracion ##\n",
    "helper.training_graph(cost_vect, acc_vect, acc_vect_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy y Matriz de confusion Training Set\n",
    "\n",
    "![alt text](https://rasbt.github.io/mlxtend/user_guide/evaluate/confusion_matrix_files/confusion_matrix_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = get_hipotesis(X_train_features, modelo_1_theta_values)\n",
    "y_predict = np.array([1 if (y > 0.5) else 0 for y in y_hat])\n",
    "\n",
    "print('Accuracy:', accuracy_score(Y_train_m1,y_predict) * 100 ,'%')\n",
    "print()\n",
    "print('Matriz de confusion')\n",
    "confusion_matrix(Y_train_m1, y_predict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy con el Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = prediccion(X_test_features, modelo_1_theta_values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:',accuracy_score(y_test, y_predict)* 100 ,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusion Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('precision: ',precision_score(y_test, y_predict))\n",
    "\n",
    "print('recall: ', recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento modelo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampleo bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Ingresa en la lista el nombre de las fatrues que quieres utlizar en este modelo (~1 linea)\n",
    "'''\n",
    "X_train_m2, Y_train_m2 = resample(X_train, y_train, n_samples = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar Features\n",
    "Solo seleccionar los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_filtro = ['mean perimeter', 'mean area','mean smoothness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m2 = helper.fitrar_nombre(X_train_m2,data.feature_names,features_filtro)\n",
    "X_test_features = helper.fitrar_nombre(X_test,data.feature_names,features_filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Numero de iteracions ##\n",
    "iterations = 1000  # Define el numero de iteraciones #\n",
    "\n",
    "## Alpha ##\n",
    "alpha = 0.05 # Define el valor de alpha #\n",
    "\n",
    "#### No hay que cambiar el codigo despues de esta linea #####\n",
    "## Numero de feautres ##\n",
    "numero_features = X_train_m2.shape[1] + 1\n",
    "\n",
    "## Creamos un vector donde se almacenan los valores de Theta,\n",
    "## lo inicializamos con numeros aleatorios\n",
    "theta_vector = np.random.rand(numero_features)\n",
    "\n",
    "## Normaliza las features de X_train_features (~1 linea) ##\n",
    "X_train_m2 = \n",
    "\n",
    "# Creando la Matriz X de features, \n",
    "# utilizamos np.ones para agregar el valor constante '1' que es el bias o feature 0\n",
    "X_train_features = np.ones((X_train_m2.shape[0], numero_features))\n",
    "X_train_features[:,:-1] = X_train_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Llama a la funcion de gradient descent, recurda definir un nombre diferente para el modelo (~1 linea) ##\n",
    "modelo_2_theta_values, cost_vect, acc_vect, acc_vect_test = \n",
    "### FIN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Funcion para graficar el costo y  accuracy durante cada iteracion ##\n",
    "helper.training_graph(cost_vect, acc_vect, acc_vect_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy con el Test set [Modelo 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = prediccion(X_test_features, modelo_2_theta_values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:',accuracy_score(y_test, y_predict)* 100 ,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusion Test Set [Modelo 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('precision: ',precision_score(y_test, y_predict))\n",
    "\n",
    "print('recall: ', recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento modelo 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampleo bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m3, Y_train_m3 = resample(X_train, y_train, n_samples = 460)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar Features\n",
    "Solo seleccionar los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Ingresa en la lista el nombre de las fatrues que quieres utlizar en este modelo (~1 linea)\n",
    "'''\n",
    "features_filtro = ['mean radius', 'mean texture', 'mean perimeter', 'mean area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m3 = helper.fitrar_nombre(X_train_m3,data.feature_names,features_filtro)\n",
    "X_test_features = helper.fitrar_nombre(X_test,data.feature_names,features_filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Numero de iteracions ##\n",
    "iterations = 1500  # Define el numero de iteraciones #\n",
    "\n",
    "## Alpha ##\n",
    "alpha = 0.02 # Define el valor de alpha #\n",
    "\n",
    "#### No hay que cambiar el codigo despues de esta linea #####\n",
    "## Numero de feautres ##\n",
    "numero_features = X_train_m3.shape[1] + 1\n",
    "\n",
    "## Creamos un vector donde se almacenan los valores de Theta,\n",
    "## lo inicializamos con numeros aleatorios\n",
    "theta_vector = np.random.rand(numero_features)\n",
    "\n",
    "## Normaliza las features de X_train_features (~1 linea) ##\n",
    "X_train_m3 = \n",
    "\n",
    "# Creando la Matriz X de features, \n",
    "# utilizamos np.ones para agregar el valor constante '1' que es el bias o feature 0\n",
    "X_train_features = np.ones((X_train_m3.shape[0], numero_features))\n",
    "X_train_features[:,:-1] = X_train_m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Llama a la funcion de gradient descent, recurda definir un nombre diferente para el modelo (~1 linea) ##\n",
    "modelo_3_theta_values, cost_vect, acc_vect, acc_vect_test = \n",
    "### FIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Funcion para graficar el costo y  accuracy durante cada iteracion\n",
    "helper.training_graph(cost_vect, acc_vect, acc_vect_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy con el Test set [Modelo 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = prediccion(X_test_features, modelo_3_theta_values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:',accuracy_score(y_test, y_predict)* 100 ,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusion Test Set [Modelo 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('precision: ',precision_score(y_test, y_predict))\n",
    "\n",
    "print('recall: ', recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento modelo 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampleo bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m4, Y_train_m4 = resample(X_train, y_train, n_samples = 460)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar Features\n",
    "Solo seleccionar los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Ingresa en la lista el nombre de las fatrues que quieres utlizar en este modelo (~1 linea)\n",
    "'''\n",
    "features_filtro = ['mean radius', 'mean texture', 'mean perimeter', 'mean area','mean smoothness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m4 = helper.fitrar_nombre(X_train_m4,data.feature_names,features_filtro)\n",
    "X_test_features = helper.fitrar_nombre(X_test,data.feature_names,features_filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Numero de iteracions ##\n",
    "iterations = 1000 # Define el numero de iteraciones #\n",
    "\n",
    "## Alpha ##\n",
    "alpha = 0.03 # Define el valor de alpha #\n",
    "\n",
    "#### No hay que cambiar el codigo despues de esta linea #####\n",
    "## Numero de feautres ##\n",
    "numero_features = X_train_m4.shape[1] + 1\n",
    "\n",
    "## Creamos un vector donde se almacenan los valores de Theta,\n",
    "## lo inicializamos con numeros aleatorios\n",
    "theta_vector = np.random.rand(numero_features)\n",
    "\n",
    "## Normaliza las features de X_train_features (~1 linea) ##\n",
    "X_train_m4 = normalizar(X_train_m4)\n",
    "\n",
    "# Creando la Matriz X de features\n",
    "X_train_features = np.ones((X_train_m4.shape[0], numero_features))\n",
    "X_train_features[:,:-1] = X_train_m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Llama a la funcion de gradient descent, recurda definir un nombre diferente para el modelo (~1 linea) ##\n",
    "modelo_4_theta_values, cost_vect, acc_vect, acc_vect_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Funcion para graficar el costo y  accuracy durante cada iteracion ##\n",
    "helper.training_graph(cost_vect, acc_vect, acc_vect_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy con el Test set [Modelo 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = prediccion(X_test_features, modelo_4_theta_values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Accuracy:',accuracy_score(y_test, y_predict)* 100 ,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusion Test Set [Modelo 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('precision: ',precision_score(y_test, y_predict))\n",
    "\n",
    "print('recall: ', recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento modelo 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampleo bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m5, Y_train_m5 = resample(X_train, y_train, n_samples = 460)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar Features\n",
    "Solo seleccionar los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Ingresa en la lista el nombre de las fatrues que quieres utlizar en este modelo (~1 linea)\n",
    "'''\n",
    "features_filtro = ['mean radius', 'mean texture', 'mean perimeter', 'mean area','mean smoothness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m5 = helper.fitrar_nombre(X_train_m5,data.feature_names,features_filtro)\n",
    "X_test_features = helper.fitrar_nombre(X_test,data.feature_names,features_filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Numero de iteracions ##\n",
    "iterations = 2000 # Define el numero de iteraciones #\n",
    "\n",
    "## Alpha ##\n",
    "alpha = 0.005 # Define el valor de alpha #\n",
    "\n",
    "#### No hay que cambiar el codigo despues de esta linea #####\n",
    "## Numero de feautres ##\n",
    "numero_features = X_train_m5.shape[1] + 1\n",
    "\n",
    "## Creamos un vector donde se almacenan los valores de Theta,\n",
    "## lo inicializamos con numeros aleatorios\n",
    "theta_vector = np.random.rand(numero_features)\n",
    "\n",
    "## Normaliza las features de X_train_features (~1 linea) ##\n",
    "X_train_m5 = normalizar(X_train_m5)\n",
    "\n",
    "# Creando la Matriz X de features\n",
    "X_train_features = np.ones((X_train_m5.shape[0], numero_features))\n",
    "X_train_features[:,:-1] = X_train_m5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Llama a la funcion de gradient descent, recurda definir un nombre diferente para el modelo (~1 linea) ##\n",
    "modelo_5_theta_values, cost_vect, acc_vect, acc_vect_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Funcion para graficar el costo y  accuracy durante cada iteracion ##\n",
    "helper.training_graph(cost_vect, acc_vect, acc_vect_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy con el Test set [Modelo 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = prediccion(X_test_features, modelo_4_theta_values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Accuracy:',accuracy_score(y_test, y_predict)* 100 ,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusion Test Set [Modelo 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('precision: ',precision_score(y_test, y_predict))\n",
    "\n",
    "print('recall: ', recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparacion de Modelos\n",
    "Es importante llevar un registro de los resultados de nuestros modelos y los hyperparametros que utilizamos, para ir comparando y ajustando los modelos. En nuestra función de gradient descent esta implementado un registro a bitacora, que almacena cada ejecucion de la funcion.\n",
    "\n",
    "Este registro almacena datos que nos van a servir para comprar los modelos y tambien almacena los valores theta del modelo, por lo que podemos guardar los modelos y utlizarlos despues.\n",
    "A continuacion vamos a desplegar en la siguiente celda y nos va ayudar a tomar una decisión de cual es el mejor modelo.\n",
    "\n",
    "Es recomendable que, luego de analizar los resultados del registro ejecutemos de nuevo alguno de los modelos cambiando los hyperparametros o numero de ejemplos y ver con cuales obtenemos mejores resultados.\n",
    "\n",
    "Podemos ejecutar la funcion `helper.guardar_log_book(log_book)` para almacenar en disco los modelos.\n",
    "\n",
    "Para el ultimo paso donde exportamos el modelo debemos utilizar la funcion `helper.filter_log_book(log_book, nombre_modelo)` para obtener el mejor modelo y exportalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.print_log_book(log_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardando la bitacora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper.guardar_log_book(log_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportar el modelo\n",
    "\n",
    "Vamos a exportar el modelo para poder hacer deploy, ** el modelo exportado debe tener las cinco primeras feautures **. Por lo cual de todos tus experimentos, selecciona el mejor modelo que cumpla con usar las 5 features ya mencionadas.\n",
    "\n",
    "Selecciona tu mejor modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionamos el mejor modelo\n",
    "\n",
    "Para seleccionar un modelo utilizamos la funcion `helper.filter_log_book()`.\n",
    "\n",
    "Esta funcion recibe de parametros la bitacora y el nombre del modelo que elegiste como el mejor\n",
    "\n",
    "`helper.filter_log_book(log_book, <nombre de nuestro mejor modelo>)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INICIO: TU CODIGO AQUI:  (~1 linea)###\n",
    "modelo = \n",
    "\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a utilizar el siguiente codigo para guardar el modelo elegido en un archivo.\n",
    "\n",
    "Esto genera 2 archivos, en un archivo _model.csv se tienen los parametros de el modelo elegido.\n",
    "\n",
    "El segundo archivo llamado _momentos.csv guarda la media y desviacion estandar de cada features, esto sera utilizado\n",
    "en la aplicacion hecha por el profesor para aplicar normalizacion al realizar predicciones.\n",
    "\n",
    "No hay que cambiar nada de codigo, solo hay que ejecutar la celda para exportar nuestro modelo y luego enviar los archivos .csv al profesor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def exportar_modelo(model,carnet):\n",
    "    norm_std, norm_media = helper.get_normalizacion_vales(X_train[:,0:5])\n",
    "    with open(carnet + '_model.csv', 'w') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        filewriter.writerow(model)\n",
    "        \n",
    "    with open(carnet + '_momentos.csv', 'w') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        filewriter.writerow(norm_std)\n",
    "        filewriter.writerow(norm_media)\n",
    "        \n",
    "    print('El modelo ha sido exportado [',csvfile.name,']')\n",
    "    \n",
    "exportar_modelo(modelo,carnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ai_cancer.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Una vez elegido y exportado tu modelo , debes enviar los archivos .csv resultantes al profesor por correo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
